{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim \n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column1</th>\n",
       "      <th>Season</th>\n",
       "      <th>Episode</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Name</th>\n",
       "      <th>N_serie</th>\n",
       "      <th>N_Season</th>\n",
       "      <th>Emision Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>winter is coming</td>\n",
       "      <td>What d’you expect? They’re savages One lot ste...</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17/04/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>winter is coming</td>\n",
       "      <td>I’ve never seen wildlings do a thing like this...</td>\n",
       "      <td>will</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17/04/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>winter is coming</td>\n",
       "      <td>How close did you get?</td>\n",
       "      <td>waymar royce</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17/04/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>winter is coming</td>\n",
       "      <td>Close as any man would</td>\n",
       "      <td>will</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17/04/2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Season 1</td>\n",
       "      <td>winter is coming</td>\n",
       "      <td>We should head back to the wall</td>\n",
       "      <td>gared</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17/04/2011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Column1    Season           Episode  \\\n",
       "0        1  Season 1  winter is coming   \n",
       "1        2  Season 1  winter is coming   \n",
       "2        3  Season 1  winter is coming   \n",
       "3        4  Season 1  winter is coming   \n",
       "4        5  Season 1  winter is coming   \n",
       "\n",
       "                                            Sentence          Name  N_serie  \\\n",
       "0  What d’you expect? They’re savages One lot ste...  waymar royce        1   \n",
       "1  I’ve never seen wildlings do a thing like this...          will        1   \n",
       "2                             How close did you get?  waymar royce        1   \n",
       "3                             Close as any man would          will        1   \n",
       "4                    We should head back to the wall         gared        1   \n",
       "\n",
       "   N_Season Emision Date  \n",
       "0         1   17/04/2011  \n",
       "1         1   17/04/2011  \n",
       "2         1   17/04/2011  \n",
       "3         1   17/04/2011  \n",
       "4         1   17/04/2011  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('got_scripts_breakdown.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to list\n",
    "data = df.Sentence.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['what', 'you', 'expect', 'they', 're', 'savages', 'one', 'lot', 'steals', 'goat', 'from', 'another', 'lot', 'and', 'before', 'you', 'know', 'it', 'they', 're', 'ripping', 'each', 'other', 'to', 'pieces']]\n"
     ]
    }
   ],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
    "\n",
    "data_words = list(sent_to_words(data))\n",
    "\n",
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['what', 'you', 'expect', 'they', 're', 'savages', 'one', 'lot', 'steals', 'goat', 'from', 'another', 'lot', 'and', 'before', 'you', 'know', 'it', 'they', 're', 'ripping', 'each_other', 'to', 'pieces']\n"
     ]
    }
   ],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# See trigram example\n",
    "print(trigram_mod[bigram_mod[data_words[0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['expect', 'savage', 'lot', 'steal', 'goat', 'lot', 'know', 'rip', 'piece']]\n"
     ]
    }
   ],
   "source": [
    "# Remove Stop Words\n",
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
    "\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 1), (1, 1), (2, 1), (3, 2), (4, 1), (5, 1), (6, 1), (7, 1)]]\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('expect', 1),\n",
       "  ('goat', 1),\n",
       "  ('know', 1),\n",
       "  ('lot', 2),\n",
       "  ('piece', 1),\n",
       "  ('rip', 1),\n",
       "  ('savage', 1),\n",
       "  ('steal', 1)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Human readable format of corpus (term-frequency)\n",
    "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=20, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           eta =10,\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (1,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (2,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (3,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (4,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (5,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (6,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (7,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (8,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (9,\n",
      "  '0.017*\"not\" + 0.011*\"be\" + 0.010*\"do\" + 0.008*\"know\" + 0.007*\"s\" + '\n",
      "  '0.007*\"man\" + 0.006*\"see\" + 0.006*\"come\" + 0.006*\"look\" + 0.005*\"go\"'),\n",
      " (10,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (11,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (12,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (13,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (14,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (15,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (16,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (17,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (18,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"'),\n",
      " (19,\n",
      "  '0.000*\"bash\" + 0.000*\"mero\" + 0.000*\"convinced\" + 0.000*\"entertainment\" + '\n",
      "  '0.000*\"appreciation\" + 0.000*\"countless\" + 0.000*\"yap\" + 0.000*\"collect\" + '\n",
      "  '0.000*\"titan\" + 0.000*\"pauper\"')]\n"
     ]
    }
   ],
   "source": [
    "# Print the Keyword in the 20 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -7.578037494869359\n",
      "\n",
      "Coherence Score:  0.5437313382396713\n"
     ]
    }
   ],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py:257: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  return pd.concat([default_term_info] + list(topic_dfs))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type complex is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    339\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyLDAvis/_display.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(data, kwds)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0mformatter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text/html'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m     formatter.for_type(PreparedData,\n\u001b[0;32m--> 313\u001b[0;31m                        lambda data, kwds=kwargs: prepared_data_to_html(data, **kwds))\n\u001b[0m\u001b[1;32m    314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyLDAvis/_display.py\u001b[0m in \u001b[0;36mprepared_data_to_html\u001b[0;34m(data, d3_url, ldavis_url, ldavis_css_url, template_type, visid, use_http)\u001b[0m\n\u001b[1;32m    176\u001b[0m                            \u001b[0md3_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md3_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m                            \u001b[0mldavis_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mldavis_url\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m                            \u001b[0mvis_json\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m                            ldavis_css_url=ldavis_css_url)\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyLDAvis/_prepare.py\u001b[0m in \u001b[0;36mto_json\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_json\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNumPyEncoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/json/__init__.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mcheck_circular\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_circular\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mallow_nan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindent\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0mseparators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseparators\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m         **kw).encode(obj)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# exceptions aren't as detailed.  The list call should be roughly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m         \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_one_shot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36miterencode\u001b[0;34m(self, o, _one_shot)\u001b[0m\n\u001b[1;32m    255\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_separator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_keys\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 self.skipkeys, _one_shot)\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,\n",
      "\u001b[0;32m/anaconda3/lib/python3.7/site-packages/pyLDAvis/utils.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    144\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mJSONEncoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.7/json/encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[0;34m(self, o)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m         \"\"\"\n\u001b[0;32m--> 179\u001b[0;31m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[1;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Object of type complex is not JSON serializable"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PreparedData(topic_coordinates=                                x        y  topics  cluster       Freq\n",
       "topic                                                                 \n",
       "9        (0.16494003385305403+0j)       0j       1        1  99.922005\n",
       "7       (-0.00868105441331865+0j)       0j       2        1   0.006701\n",
       "17     (-0.008681054413318652+0j)       0j       3        1   0.006395\n",
       "0      (-0.008681054413318652+0j)       0j       4        1   0.005537\n",
       "10     (-0.008681054413318652+0j)       0j       5        1   0.005143\n",
       "18      (-0.00868105441331864+0j)  (-0+0j)       6        1   0.004208\n",
       "2       (-0.00868105441331864+0j)  (-0+0j)       7        1   0.003924\n",
       "5       (-0.00868105441331864+0j)  (-0+0j)       8        1   0.003815\n",
       "4       (-0.00868105441331864+0j)  (-0+0j)       9        1   0.003760\n",
       "6       (-0.00868105441331864+0j)  (-0+0j)      10        1   0.003715\n",
       "11      (-0.00868105441331864+0j)  (-0+0j)      11        1   0.003700\n",
       "12      (-0.00868105441331864+0j)  (-0+0j)      12        1   0.003651\n",
       "3       (-0.00868105441331864+0j)       0j      13        1   0.003621\n",
       "1       (-0.00868105441331864+0j)       0j      14        1   0.003538\n",
       "16      (-0.00868105441331864+0j)       0j      15        1   0.003515\n",
       "14      (-0.00868105441331864+0j)       0j      16        1   0.003469\n",
       "19      (-0.00868105441331864+0j)  (-0+0j)      17        1   0.003446\n",
       "13     (-0.008681054413318644+0j)       0j      18        1   0.003322\n",
       "15     (-0.008681054413318628+0j)       0j      19        1   0.003297\n",
       "8      (-0.008681054413318628+0j)       0j      20        1   0.003245, topic_info=     Category         Freq           Term        Total  loglift  logprob\n",
       "558   Default  1448.000000             be  1448.000000  30.0000   30.000\n",
       "53    Default  1307.000000             do  1307.000000  29.0000   29.000\n",
       "560   Default  2125.000000            not  2125.000000  28.0000   28.000\n",
       "2     Default   982.000000           know   982.000000  27.0000   27.000\n",
       "571   Default   952.000000              s   952.000000  26.0000   26.000\n",
       "16    Default   928.000000            man   928.000000  25.0000   25.000\n",
       "11    Default   801.000000            see   801.000000  24.0000   24.000\n",
       "90    Default   784.000000           come   784.000000  23.0000   23.000\n",
       "112   Default   728.000000           look   728.000000  22.0000   22.000\n",
       "48    Default   657.000000             go   657.000000  21.0000   21.000\n",
       "44    Default   651.000000           want   651.000000  20.0000   20.000\n",
       "679   Default   632.000000           have   632.000000  19.0000   19.000\n",
       "15    Default   576.000000            get   576.000000  18.0000   18.000\n",
       "29    Default   565.000000          think   565.000000  17.0000   17.000\n",
       "49    Default   503.000000         father   503.000000  16.0000   16.000\n",
       "714   Default   499.000000           walk   499.000000  15.0000   15.000\n",
       "42    Default   496.000000            say   496.000000  14.0000   14.000\n",
       "18    Default   496.000000           back   496.000000  13.0000   13.000\n",
       "80    Default   469.000000           lord   469.000000  12.0000   12.000\n",
       "91    Default   468.000000           tell   468.000000  11.0000   11.000\n",
       "151   Default   464.000000           take   464.000000  10.0000   10.000\n",
       "17    Default   442.000000          would   442.000000   9.0000    9.000\n",
       "116   Default   440.000000          north   440.000000   8.0000    8.000\n",
       "540   Default   438.000000           turn   438.000000   7.0000    7.000\n",
       "33    Default   435.000000           kill   435.000000   6.0000    6.000\n",
       "414   Default   435.000000           make   435.000000   5.0000    5.000\n",
       "40    Default   431.000000           good   431.000000   4.0000    4.000\n",
       "210   Default   417.000000          queen   417.000000   3.0000    3.000\n",
       "10    Default   409.000000          never   409.000000   2.0000    2.000\n",
       "12    Default   406.000000          thing   406.000000   1.0000    1.000\n",
       "...       ...          ...            ...          ...      ...      ...\n",
       "3096  Topic20     0.000594         stress     5.834192   1.1427   -8.853\n",
       "3150  Topic20     0.000594          lorch     5.834280   1.1427   -8.853\n",
       "3148  Topic20     0.000594          amory     5.834414   1.1427   -8.853\n",
       "3133  Topic20     0.000594        succumb     5.834272   1.1427   -8.853\n",
       "3129  Topic20     0.000594          stoat     5.834194   1.1427   -8.853\n",
       "3128  Topic20     0.000594       stockade     5.834311   1.1427   -8.853\n",
       "6994  Topic20     0.000594       annoying    91.034645  -1.6048   -8.853\n",
       "2323  Topic20     0.000594      swordplay     5.837357   1.1422   -8.853\n",
       "2324  Topic20     0.000594       braavosi     5.937723   1.1251   -8.853\n",
       "2326  Topic20     0.000594       familiar    11.787561   0.4394   -8.853\n",
       "2327  Topic20     0.000594         escape    21.015272  -0.1388   -8.853\n",
       "2328  Topic20     0.000594         engage     5.976397   1.1186   -8.853\n",
       "2329  Topic20     0.000594          grief     6.638994   1.0135   -8.853\n",
       "2330  Topic20     0.000594        unarmed     6.432274   1.0451   -8.853\n",
       "2332  Topic20     0.000594          sadly     5.851550   1.1397   -8.853\n",
       "2333  Topic20     0.000594           slit     6.038658   1.1083   -8.853\n",
       "2335  Topic20     0.000594           sign     8.999290   0.7093   -8.853\n",
       "2348  Topic20     0.000594           urge     5.836761   1.1423   -8.853\n",
       "2336  Topic20     0.000594         awhile    20.193346  -0.0989   -8.853\n",
       "2337  Topic20     0.000594        examine    23.393242  -0.2460   -8.853\n",
       "2338  Topic20     0.000594  maester_aemon     6.888963   0.9765   -8.853\n",
       "2339  Topic20     0.000594          await     5.943985   1.1241   -8.853\n",
       "2340  Topic20     0.000594         gently     5.837757   1.1421   -8.853\n",
       "2341  Topic20     0.000594          prove    23.648476  -0.2569   -8.853\n",
       "2342  Topic20     0.000594           plot    16.180765   0.1226   -8.853\n",
       "2344  Topic20     0.000594        consort     6.089759   1.0998   -8.853\n",
       "2345  Topic20     0.000594            eld     6.164834   1.0876   -8.853\n",
       "2346  Topic20     0.000594         arrest     7.284510   0.9207   -8.853\n",
       "2321  Topic20     0.000594            bar    26.851654  -0.3839   -8.853\n",
       "2320  Topic20     0.000594         scrape     5.837546   1.1421   -8.853\n",
       "\n",
       "[8477 rows x 6 columns], token_table=      Topic      Freq        Term\n",
       "term                             \n",
       "1922      1  1.028425     abiding\n",
       "630       1  1.028426       abode\n",
       "1945      1  1.028425    absentee\n",
       "561       1  1.028426   abundance\n",
       "3274      1  1.028418  accusation\n",
       "2283      1  1.028425       acorn\n",
       "1160      1  1.028426  admittedly\n",
       "1877      1  1.028425     adviser\n",
       "738       1  1.028426      aleena\n",
       "1501      1  1.028425    amarylli\n",
       "3148      1  1.028381       amory\n",
       "6994      1  0.999619    annoying\n",
       "2314      1  1.028424   apartment\n",
       "1288      1  1.028426       arakh\n",
       "1760      1  1.028425     archery\n",
       "1440      1  1.028425    archonel\n",
       "2346      1  0.960943      arrest\n",
       "2086      1  1.028425     attaint\n",
       "847       1  1.028426     attract\n",
       "2339      1  1.009424       await\n",
       "2336      1  0.990425      awhile\n",
       "2117      1  1.028425        axel\n",
       "18        1  0.999662        back\n",
       "1170      1  1.028426      ballad\n",
       "1007      1  1.028426    bankrupt\n",
       "2321      1  1.005525         bar\n",
       "2508      1  1.028424   battleaxe\n",
       "2980      1  1.028411      bauble\n",
       "558       1  1.000253          be\n",
       "734       1  1.028426       becca\n",
       "...     ...       ...         ...\n",
       "1453      1  1.028425  vermithrax\n",
       "1704      1  1.028425       vigil\n",
       "2620      1  1.028423     violent\n",
       "2265      1  1.028425      vorkoy\n",
       "1297      1  1.028426        vroz\n",
       "2485      1  1.028424     waldron\n",
       "714       1  0.999656        walk\n",
       "44        1  1.000381        want\n",
       "1539      1  1.028425      warmer\n",
       "678       1  1.028426     whatnot\n",
       "1376      1  1.028425  whereabout\n",
       "779       1  1.028426   whetstone\n",
       "2635      1  1.028423       whiff\n",
       "500       1  1.028426     widowed\n",
       "2621      1  1.028423   widowhood\n",
       "1997      1  1.028425       wilde\n",
       "637       1  1.028426      wintry\n",
       "3275      1  1.028418    withdraw\n",
       "2929      1  1.028422        wive\n",
       "1486      1  1.028425         woe\n",
       "2618      1  1.028424   wolfswood\n",
       "3379      1  1.028417      worked\n",
       "17        1  1.000938       would\n",
       "1777      1  1.028422       wrath\n",
       "1895      1  1.028425         wyl\n",
       "740       1  1.028426       wylla\n",
       "2097      1  1.028425        yank\n",
       "1655      1  1.028425      yanked\n",
       "1365      1  1.028426      yearle\n",
       "3092      1  1.028402      zuriff\n",
       "\n",
       "[473 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[10, 8, 18, 1, 11, 19, 3, 6, 5, 7, 12, 13, 4, 2, 17, 15, 20, 14, 16, 9])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Download File: http://mallet.cs.umass.edu/dist/mallet-2.0.8.zip\n",
    "# mallet_path = '/Users/joycechen/Desktop/ML/SM_Project/mallet-2.0.8/bin/mallet'  # update this path\n",
    "# ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=20, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "#         model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=num_topics, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_lemmatized, start=5, limit=60, step=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "limit=60; start=5; step=5;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Topics = 5  has Coherence Value of 0.3931\n",
      "Num Topics = 10  has Coherence Value of 0.3492\n",
      "Num Topics = 15  has Coherence Value of 0.3524\n",
      "Num Topics = 20  has Coherence Value of 0.3502\n",
      "Num Topics = 25  has Coherence Value of 0.3521\n",
      "Num Topics = 30  has Coherence Value of 0.4352\n",
      "Num Topics = 35  has Coherence Value of 0.5836\n",
      "Num Topics = 40  has Coherence Value of 0.5854\n",
      "Num Topics = 45  has Coherence Value of 0.5702\n",
      "Num Topics = 50  has Coherence Value of 0.5527\n",
      "Num Topics = 55  has Coherence Value of 0.5575\n"
     ]
    }
   ],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.236*\"way\" + 0.115*\"fuck\" + 0.098*\"mean\" + 0.076*\"city\" + 0.058*\"choose\" + '\n",
      "  '0.049*\"someone\" + 0.048*\"old\" + 0.039*\"robert\" + 0.034*\"new\" + '\n",
      "  '0.027*\"hunt\"'),\n",
      " (1,\n",
      "  '0.181*\"never\" + 0.180*\"thing\" + 0.127*\"hand\" + 0.127*\"ever\" + 0.106*\"wall\" '\n",
      "  '+ 0.090*\"head\" + 0.060*\"life\" + 0.038*\"south\" + 0.000*\"not\" + 0.000*\"be\"'),\n",
      " (2,\n",
      "  '0.391*\"know\" + 0.258*\"want\" + 0.199*\"father\" + 0.043*\"hold\" + 0.028*\"lie\" + '\n",
      "  '0.000*\"not\" + 0.000*\"be\" + 0.000*\"s\" + 0.000*\"have\" + 0.000*\"make\"'),\n",
      " (3,\n",
      "  '0.355*\"look\" + 0.275*\"think\" + 0.131*\"die\" + 0.077*\"ask\" + 0.061*\"bran\" + '\n",
      "  '0.000*\"not\" + 0.000*\"be\" + 0.000*\"s\" + 0.000*\"turn\" + 0.000*\"walk\"'),\n",
      " (4,\n",
      "  '0.442*\"man\" + 0.184*\"king\" + 0.117*\"run\" + 0.081*\"sister\" + '\n",
      "  '0.034*\"mountain\" + 0.033*\"rest\" + 0.007*\"lion\" + 0.004*\"andal\" + '\n",
      "  '0.000*\"quick\" + 0.000*\"not\"'),\n",
      " (5,\n",
      "  '0.269*\"take\" + 0.215*\"jon\" + 0.117*\"love\" + 0.066*\"anything\" + '\n",
      "  '0.052*\"kings_lande\" + 0.048*\"raven\" + 0.026*\"casterly_rock\" + '\n",
      "  '0.026*\"afraid\" + 0.025*\"water\" + 0.022*\"foot\"'),\n",
      " (6,\n",
      "  '0.424*\"tell\" + 0.243*\"give\" + 0.145*\"night\" + 0.000*\"not\" + 0.000*\"be\" + '\n",
      "  '0.000*\"s\" + 0.000*\"use\" + 0.000*\"ill\" + 0.000*\"crow\" + 0.000*\"have\"'),\n",
      " (7,\n",
      "  '0.317*\"back\" + 0.132*\"away\" + 0.112*\"first\" + 0.066*\"true\" + 0.057*\"drink\" '\n",
      "  '+ 0.053*\"horse\" + 0.049*\"forgive\" + 0.042*\"course\" + 0.028*\"white_walker\" + '\n",
      "  '0.012*\"catch\"'),\n",
      " (8,\n",
      "  '0.299*\"go\" + 0.262*\"get\" + 0.197*\"kill\" + 0.097*\"stark\" + '\n",
      "  '0.051*\"understand\" + 0.000*\"not\" + 0.000*\"be\" + 0.000*\"s\" + 0.000*\"have\" + '\n",
      "  '0.000*\"walk\"'),\n",
      " (9,\n",
      "  '0.390*\"see\" + 0.145*\"people\" + 0.111*\"sword\" + 0.105*\"family\" + '\n",
      "  '0.053*\"word\" + 0.033*\"far\" + 0.023*\"break\" + 0.017*\"pass\" + 0.014*\"swing\" + '\n",
      "  '0.009*\"coward\"'),\n",
      " (10,\n",
      "  '0.400*\"do\" + 0.134*\"would\" + 0.110*\"dead\" + 0.105*\"well\" + 0.061*\"house\" + '\n",
      "  '0.047*\"name\" + 0.038*\"work\" + 0.025*\"close\" + 0.008*\"fine\" + '\n",
      "  '0.006*\"baratheon\"'),\n",
      " (11,\n",
      "  '0.163*\"long\" + 0.151*\"lannister\" + 0.145*\"lady\" + 0.104*\"nothing\" + '\n",
      "  '0.096*\"mother\" + 0.088*\"day\" + 0.036*\"honor\" + 0.026*\"train\" + 0.024*\"fool\" '\n",
      "  '+ 0.013*\"feed\"'),\n",
      " (12,\n",
      "  '0.405*\"come\" + 0.137*\"still\" + 0.081*\"last\" + 0.042*\"rule\" + 0.040*\"feel\" + '\n",
      "  '0.038*\"swear\" + 0.033*\"god\" + 0.026*\"northern\" + 0.024*\"better\" + '\n",
      "  '0.024*\"death\"'),\n",
      " (13,\n",
      "  '0.277*\"could\" + 0.179*\"child\" + 0.164*\"even\" + 0.088*\"year\" + '\n",
      "  '0.043*\"thousand\" + 0.040*\"belong\" + 0.000*\"not\" + 0.000*\"be\" + 0.000*\"s\" + '\n",
      "  '0.000*\"have\"'),\n",
      " (14,\n",
      "  '0.122*\"expect\" + 0.121*\"lot\" + 0.120*\"young\" + 0.111*\"sorry\" + '\n",
      "  '0.071*\"steal\" + 0.022*\"piece\" + 0.007*\"goat\" + 0.004*\"rip\" + 0.000*\"be\" + '\n",
      "  '0.000*\"unmarried\"'),\n",
      " (15,\n",
      "  '0.242*\"find\" + 0.203*\"bring\" + 0.109*\"perhaps\" + 0.085*\"seem\" + '\n",
      "  '0.080*\"snow\" + 0.053*\"move\" + 0.000*\"not\" + 0.000*\"be\" + 0.000*\"s\" + '\n",
      "  '0.000*\"make\"'),\n",
      " (16,\n",
      "  '0.297*\"brother\" + 0.173*\"much\" + 0.121*\"show\" + 0.040*\"worry\" + '\n",
      "  '0.023*\"warn\" + 0.010*\"duty\" + 0.000*\"not\" + 0.000*\"be\" + 0.000*\"s\" + '\n",
      "  '0.000*\"dragon\"'),\n",
      " (17,\n",
      "  '0.204*\"lord\" + 0.168*\"need\" + 0.091*\"watch\" + 0.084*\"tyrion\" + '\n",
      "  '0.058*\"winter\" + 0.049*\"ride\" + 0.047*\"boy\" + 0.043*\"put\" + 0.029*\"order\" + '\n",
      "  '0.026*\"quite\"'),\n",
      " (18,\n",
      "  '0.222*\"north\" + 0.217*\"good\" + 0.210*\"queen\" + 0.118*\"winterfell\" + '\n",
      "  '0.104*\"keep\" + 0.012*\"protector\" + 0.007*\"news\" + 0.007*\"realm\" + '\n",
      "  '0.000*\"practice\" + 0.000*\"not\"'),\n",
      " (19,\n",
      "  '0.486*\"say\" + 0.210*\"always\" + 0.075*\"wildling\" + 0.028*\"trouble\" + '\n",
      "  '0.000*\"not\" + 0.000*\"s\" + 0.000*\"have\" + 0.000*\"be\" + 0.000*\"believe\" + '\n",
      "  '0.000*\"nice\"')]\n"
     ]
    }
   ],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3] # here k = 20, the topics start getting repetative at k = 25 \n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
